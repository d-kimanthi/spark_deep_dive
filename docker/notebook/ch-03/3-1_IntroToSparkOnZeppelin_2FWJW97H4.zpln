{
  "paragraphs": [
    {
      "text": "%md\n# Introduction to Spark on Zeppelin\nIf you are seeing this then you were able to get your local environment running. Congrats.",
      "user": "anonymous",
      "dateUpdated": "2021-01-31 19:52:07.578",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eIntroduction to Spark on Zeppelin\u003c/h1\u003e\n\u003cp\u003eIf you are seeing this then you were able to get your local environment running. Congrats.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610833094066_1219732012",
      "id": "paragraph_1610833094066_1219732012",
      "dateCreated": "2021-01-16 21:38:14.073",
      "dateStarted": "2021-01-31 19:52:07.617",
      "dateFinished": "2021-01-31 19:52:08.990",
      "status": "FINISHED"
    },
    {
      "text": "%spark\n// shows the spark settings and primes the spark session and context\nspark.sparkContext.getConf.toDebugString",
      "user": "anonymous",
      "dateUpdated": "2025-11-22 22:57:59.167",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres1\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d\nPYSPARK_DRIVER_PYTHON\u003dpython\nPYSPARK_PYTHON\u003dpython\nSPARK_HOME\u003d/spark\nspark.app.id\u003dlocal-1763852300431\nspark.app.initial.jar.urls\u003dspark://zeppelin:43971/jars/spark-interpreter-0.12.0.jar\nspark.app.name\u003dspark-shared_process\nspark.app.startTime\u003d1763852298759\nspark.app.submitTime\u003d1763852288308\nspark.driver.cores\u003d1\nspark.driver.extraClassPath\u003d:/opt/zeppelin/local-repo/spark/*:/opt/zeppelin/interpreter/spark/*:::/opt/zeppelin/interpreter/zeppelin-interpreter-shaded-0.12.0.jar:/opt/zeppelin/interpreter/spark/spark-interpreter-0.12.0.jar\nspark.driver.extraJavaOptions\u003d-Djava.net.preferIPv6Addresses\u003dfalse -XX:+IgnoreUnrecognizedVMOptions --add-opens\u003djava.base/java.lang\u003dALL-UNNAMED --add-opens\u003djava.base/java.lang.invoke\u003dALL-UNNAMED --add-opens\u003djava.base/jav...\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610320103402_199331554",
      "id": "paragraph_1610320103402_199331554",
      "dateCreated": "2021-01-10 23:08:23.402",
      "dateStarted": "2025-11-22 22:57:59.235",
      "dateFinished": "2025-11-22 22:58:42.996",
      "status": "FINISHED"
    },
    {
      "text": "%md\n## Read and Analyze\nThis next paragraph shows the most basic of Spark methods for file based reading. The zero-bells attached `spark.read.text`.\nThis is useful technique if you are working data for the first time and don\u0027t know how to parse it, or maybe are having issues using other methods for automatic parsing.\n",
      "user": "anonymous",
      "dateUpdated": "2021-01-31 19:52:27.674",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eRead and Analyze\u003c/h2\u003e\n\u003cp\u003eThis next paragraph shows the most basic of Spark methods for file based reading. The zero-bells attached \u003ccode\u003espark.read.text\u003c/code\u003e.\u003cbr /\u003e\nThis is useful technique if you are working data for the first time and don\u0026rsquo;t know how to parse it, or maybe are having issues using other methods for automatic parsing.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610832378788_1358698633",
      "id": "paragraph_1610832378788_1358698633",
      "dateCreated": "2021-01-16 21:26:18.795",
      "dateStarted": "2021-01-31 19:52:27.690",
      "dateFinished": "2021-01-31 19:52:27.709",
      "status": "FINISHED"
    },
    {
      "title": "Read and Analyze",
      "text": "%spark\n// parse the raw coffee file. this is a simple csv file without headers. The goal is to build core skills: parsing, exploring data\n// format: name, boldness\n\nval df \u003d spark.read.text(\"file:///learn/raw-coffee.txt\")\n// df.printSchema\ndf.head()",
      "user": "anonymous",
      "dateUpdated": "2025-11-22 23:00:10.340",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [value: string]\n\u001b[1m\u001b[34mres3\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Row\u001b[0m \u003d [folgers, 10]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d0"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610320158652_480149",
      "id": "paragraph_1610320158652_480149",
      "dateCreated": "2021-01-10 23:09:18.653",
      "dateStarted": "2025-11-22 23:00:10.355",
      "dateFinished": "2025-11-22 23:00:15.267",
      "status": "FINISHED"
    },
    {
      "text": "%spark\ndf.show()",
      "user": "anonymous",
      "dateUpdated": "2025-11-22 23:03:58.786",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------+\n|         value|\n+--------------+\n|   folgers, 10|\n|     yuban, 10|\n| nespresso, 10|\n|     ritual, 4|\n|four barrel, 5|\n+--------------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d1"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1763852551546_592326339",
      "id": "paragraph_1763852551546_592326339",
      "dateCreated": "2025-11-22 23:02:31.547",
      "dateStarted": "2025-11-22 23:03:58.811",
      "dateFinished": "2025-11-22 23:04:01.481",
      "status": "FINISHED"
    },
    {
      "text": "%spark\nval converted \u003d df.map { r \u003d\u003e\n            r.getString(0).split(\",\") match {\n            case Array(name:String,roast:String) \u003d\u003e\n            (name,roast.trim.toInt)\n            }\n            }.toDF(\"name\",\"roast\")\nconverted.printSchema",
      "user": "anonymous",
      "dateUpdated": "2025-11-22 23:05:39.857",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- name: string (nullable \u003d true)\n |-- roast: integer (nullable \u003d false)\n\n\u001b[1m\u001b[34mconverted\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [name: string, roast: int]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1763852638808_246253483",
      "id": "paragraph_1763852638808_246253483",
      "dateCreated": "2025-11-22 23:03:58.810",
      "dateStarted": "2025-11-22 23:05:39.871",
      "dateFinished": "2025-11-22 23:05:44.627",
      "status": "FINISHED"
    },
    {
      "text": "%spark\nconverted.show()",
      "user": "anonymous",
      "dateUpdated": "2025-11-22 23:07:14.411",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-----------+-----+\n|       name|roast|\n+-----------+-----+\n|    folgers|   10|\n|      yuban|   10|\n|  nespresso|   10|\n|     ritual|    4|\n|four barrel|    5|\n+-----------+-----+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d2"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1763852739869_347394037",
      "id": "paragraph_1763852739869_347394037",
      "dateCreated": "2025-11-22 23:05:39.871",
      "dateStarted": "2025-11-22 23:07:14.425",
      "dateFinished": "2025-11-22 23:07:16.750",
      "status": "FINISHED"
    },
    {
      "text": "%spark\n",
      "user": "anonymous",
      "dateUpdated": "2025-11-22 23:07:14.429",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1763852834421_1724391644",
      "id": "paragraph_1763852834421_1724391644",
      "dateCreated": "2025-11-22 23:07:14.424",
      "status": "READY"
    }
  ],
  "name": "3-1_IntroToSparkOnZeppelin",
  "id": "2FWJW97H4",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0-preview2",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}